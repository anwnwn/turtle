{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ameya Dehade**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "date_iterations = [\n",
    "        \n",
    "    # Entire Period\n",
    "    ('2010-02-01', '2024-02-01'),\n",
    "    \n",
    "    # 2 year periods\n",
    "    ('2022-02-01', '2024-02-01'),\n",
    "    ('2020-02-01', '2022-02-01'),\n",
    "    ('2018-02-01', '2020-02-01'),\n",
    "    ('2016-02-01', '2018-02-01'),\n",
    "    ('2014-02-01', '2016-02-01'),\n",
    "    ('2012-02-01', '2014-02-01'),\n",
    "    ('2010-02-01', '2012-02-01'),\n",
    "    \n",
    "    # 3 year periods\n",
    "    ('2021-02-01', '2024-02-01'),\n",
    "    ('2018-02-01', '2021-02-01'),\n",
    "    ('2015-02-01', '2018-02-01'),\n",
    "    ('2012-02-01', '2015-02-01'),\n",
    "    ('2010-02-01', '2013-02-01'),\n",
    "    \n",
    "    # 4 year periods\n",
    "    ('2020-02-01', '2024-02-01'),\n",
    "    ('2016-02-01', '2020-02-01'),\n",
    "    ('2012-02-01', '2016-02-01'),\n",
    "    ('2010-02-01', '2014-02-01'),\n",
    "    \n",
    "    # 5 year periods\n",
    "    ('2019-02-01', '2024-02-01'),\n",
    "    ('2014-02-01', '2019-02-01'),\n",
    "    ('2010-02-01', '2015-02-01'),\n",
    "    \n",
    "    # 6 year periods\n",
    "    ('2018-02-01', '2024-02-01'),\n",
    "    ('2012-02-01', '2018-02-01'),\n",
    "    ('2010-02-01', '2016-02-01'),\n",
    "    \n",
    "    # 8 year periods\n",
    "    ('2016-02-01', '2024-02-01'),\n",
    "    ('2010-02-01', '2018-02-01'),\n",
    "]\n",
    "\n",
    "atr_period_iterations = [\n",
    "    7,\n",
    "    10,\n",
    "    14,\n",
    "    17,\n",
    "    28,\n",
    "    32, \n",
    "    35,\n",
    "    42,\n",
    "    49,\n",
    "    56,\n",
    "    63\n",
    "]\n",
    "\n",
    "X = [\n",
    "    1,\n",
    "    2,\n",
    "    3,\n",
    "    4,\n",
    "    5,\n",
    "    6,\n",
    "    7,\n",
    "    8\n",
    "]\n",
    "\n",
    "Y = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_datareader import data as pdr \n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('IBOVDia_03-04-24.csv')\n",
    "tickers = df['Code'].values\n",
    "end = len(tickers) - 2\n",
    "mySymbols = [s + '.SA' for s in tickers[:end]]\n",
    "\n",
    "# Overall time period\n",
    "START_DATE = '2010-02-01'\n",
    "TRUNCATE_DATE = '2011-02-01'\n",
    "END_DATE = '2024-02-01'\n",
    "\n",
    "priceTablesByTicker = {}\n",
    "\n",
    "priceTable = pd.read_csv('priceTable.csv', parse_dates=[0])\n",
    "priceTable.set_index(priceTable.columns[0], inplace=True)\n",
    "\n",
    "for ticker in mySymbols:\n",
    "    currTable = pd.read_csv(ticker + '_price_table.csv', parse_dates=[0])\n",
    "    currTable.set_index(currTable.columns[0], inplace=True)\n",
    "    priceTablesByTicker[ticker] = currTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def normalize(panel_data):\n",
    "    return panel_data.sub(panel_data.mean(axis=1), axis=0).div(panel_data.std(axis=1),axis=0)\n",
    "\n",
    "# This function takes a panel of positions and returns a time series of returns (in $).\n",
    "def returns_from_positions(position_data, df_rtn, truncate_date):\n",
    "    return (position_data * df_rtn).truncate(before=truncate_date).sum(axis=1)\n",
    "\n",
    "# This function takes a time series of daily returns & returns an annualized Sharpe ratio.\n",
    "def sharpe_ratio(daily_return_series):\n",
    "    return round(daily_return_series.mean() / daily_return_series.std() * 252**0.5, 2)\n",
    "\n",
    "def rank_bin(panel_data, alpha):\n",
    "    if alpha <=0 or alpha>=0.5:\n",
    "        raise ValueError(\"Alpha should be greater than 0- and less than 0.5\")\n",
    "    return panel_data.apply(pd.qcut, axis=1, args=([0, alpha, 1-alpha, 1.],), labels=[-1,0,1]).astype(\"float64\")\n",
    "\n",
    "def benchmark_strategies(priceTable, start_date, end_date):\n",
    "    rtn = priceTable.loc[start_date:end_date].pct_change()*100\n",
    "    truncate_date = pd.to_datetime(start_date) + pd.DateOffset(years=1)\n",
    "    # mean reversion signal based on r(t-5) + ... + r(t-1)\n",
    "    mr_sig_raw = -rtn.shift(1).rolling(5).sum().dropna(how='all')\n",
    "    # momentum signal based on r(t-252) + ... + r(t-22)\n",
    "    mom_sig_raw = rtn.shift(22).rolling(231).sum().dropna(how='all')\n",
    "    print(mom_sig_raw.shape)\n",
    "    # Go long $1 for the top 40%, short $1 for the bottom 40%, and flat for the middle 20%.\n",
    "    mom_ranked_position = rank_bin(mom_sig_raw, 0.4)\n",
    "    mr_ranked_position = rank_bin(mr_sig_raw, 0.4)\n",
    "\n",
    "    mom_rtn = returns_from_positions(mom_ranked_position, rtn, truncate_date)\n",
    "    mr_rtn  = returns_from_positions(mr_ranked_position,  rtn, truncate_date)\n",
    "    \n",
    "    mr_SR = sharpe_ratio(mr_rtn)\n",
    "    mom_SR = sharpe_ratio(mom_rtn)\n",
    "\n",
    "    both_rtn = 0.5*mom_rtn + 0.5*mr_rtn  # This is the return of a 50/50 portfolio of both strategies.\n",
    "    both_SR = sharpe_ratio(both_rtn)\n",
    "    \n",
    "    return mom_rtn.cumsum()/mom_rtn.std()*0.15, mr_rtn.cumsum()/mr_rtn.std()*0.15, both_rtn.cumsum()/both_rtn.std()*0.15, mom_SR, mr_SR, both_SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_atr(stock_data, period=14):\n",
    "    high_low = stock_data['High'] - stock_data['Low']\n",
    "    high_close = np.abs(stock_data['High'] - stock_data['Close'].shift())\n",
    "    low_close = np.abs(stock_data['Low'] - stock_data['Close'].shift())\n",
    "    tr = pd.DataFrame({'high_low': high_low, 'high_close': high_close, 'low_close': low_close}).max(axis=1)\n",
    "    atr = tr.rolling(window=period).mean()\n",
    "    return atr\n",
    "\n",
    "def turtle_atr(stock, atr_period=14, X=2, Y=2):\n",
    "    # Calculate high, low, avg for original turtle strategy\n",
    "    stock['high'] = stock['Close'].shift(1).rolling(window=5).max()  # 5 day high\n",
    "    stock['low'] = stock['Close'].shift(1).rolling(window=5).min()   # 5 day low\n",
    "    stock['avg'] = stock['Close'].shift(1).rolling(window=5).mean()  # 5 day mean\n",
    "\n",
    "    # Calculate ATR\n",
    "    stock['ATR'] = calculate_atr(stock, atr_period)\n",
    "\n",
    "    #og turtle\n",
    "    stock['long_entry'] = stock['Close'] > stock['high']\n",
    "    stock['short_entry'] = stock['Close'] < stock['low']\n",
    "    stock['long_exit'] = stock['Close'] < stock['avg']\n",
    "    stock['short_exit'] = stock['Close'] > stock['avg']\n",
    "\n",
    "    stock['positions_long'] = np.nan\n",
    "    stock.loc[stock['long_entry'], 'positions_long'] = 1\n",
    "    stock.loc[stock['long_exit'], 'positions_long'] = 0\n",
    "\n",
    "    stock['positions_short'] = np.nan\n",
    "    stock.loc[stock['short_entry'], 'positions_short'] = -1\n",
    "    stock.loc[stock['short_exit'], 'positions_short'] = 0\n",
    "\n",
    "    \n",
    "    '''atr stuff (warning: may not work)'''\n",
    "    #ATR stop loss and new position barrier logic\n",
    "    stock['long_stop_loss'] = stock['Close'] - (X * stock['ATR'])\n",
    "    stock['short_stop_loss'] = stock['Close'] + (X * stock['ATR'])\n",
    "    \n",
    "        # adj stop loss when a new high/low is reached\n",
    "    stock['long_stop_loss'] = np.where((stock['Close'] > stock['high']) & (stock['positions_long'] == 1), \n",
    "                                       stock['Close'] - (X * stock['ATR']), \n",
    "                                       stock['long_stop_loss'])\n",
    "                            \n",
    "    stock['short_stop_loss'] = np.where((stock['Close'] < stock['low']) & (stock['positions_short'] == -1), \n",
    "                                        stock['Close'] + (X * stock['ATR']), \n",
    "                                        stock['short_stop_loss'])\n",
    "\n",
    "    # sliding stop loss\n",
    "    stock['long_stop_loss'] = stock['long_stop_loss'].ffill().where(stock['positions_long'] == 1)\n",
    "    stock['short_stop_loss'] = stock['short_stop_loss'].ffill().where(stock['positions_short'] == -1)\n",
    "\n",
    "    #exit positions based on stop loss\n",
    "    stock.loc[stock['Close'] < stock['long_stop_loss'], 'positions_long'] = 0\n",
    "    stock.loc[stock['Close'] > stock['short_stop_loss'], 'positions_short'] = 0\n",
    "\n",
    "#     #exclusion zones\n",
    "#     stock['long_exclusion_zone'] = stock['Close'] + (Y * stock['ATR'])\n",
    "#     stock['short_exclusion_zone'] = stock['Close'] - (Y * stock['ATR'])\n",
    "#     stock.loc[stock['Close'] < stock['long_exclusion_zone'], 'positions_long'] = 0\n",
    "#     stock.loc[stock['Close'] > stock['short_exclusion_zone'], 'positions_short'] = 0\n",
    "    \n",
    "    \n",
    "    # last stopped position\n",
    "    stock['last_long_stop_out'] = ((stock['Close'] < stock['long_stop_loss']) & (stock['positions_long'].shift(1) == 1))\n",
    "    stock['last_short_stop_out'] = ((stock['Close'] > stock['short_stop_loss']) & (stock['positions_short'].shift(1) == -1))\n",
    "\n",
    "    # exclusion zones using 'shift(1)' to use the previous close to avoid looking ahead\n",
    "    stock['long_exclusion_zone'] = stock['Close'].shift(1) + (Y * stock['ATR'].shift(1))\n",
    "    stock['short_exclusion_zone'] = stock['Close'].shift(1) - (Y * stock['ATR'].shift(1))\n",
    "\n",
    "    # apply exclusion zones to prevent trades\n",
    "    stock.loc[stock['last_long_stop_out'], 'long_entry'] = False\n",
    "    stock.loc[stock['Close'] < stock['long_exclusion_zone'], 'long_entry'] = False\n",
    "\n",
    "    stock.loc[stock['last_short_stop_out'], 'short_entry'] = False\n",
    "    stock.loc[stock['Close'] > stock['short_exclusion_zone'], 'short_entry'] = False\n",
    "\n",
    "    \n",
    "    #TODO: how to process entry/exit signals to affect the actual stock positions?\n",
    "    \n",
    "    stock.loc[(stock['positions_long'].shift(1) == 1), 'long_entry'] = False\n",
    "    stock.loc[(stock['positions_short'].shift(1) == -1), 'short_entry'] = False\n",
    "    stock['positions_long'] = stock['positions_long'].ffill().fillna(0)\n",
    "    stock['positions_short'] = stock['positions_short'].ffill().fillna(0)\n",
    "\n",
    "    # we can't enter a long position if we're in an exclusion zone or have a short position (vice versa for short)\n",
    "    stock.loc[(stock['long_exclusion_zone'] > stock['Close']) | (stock['positions_short'] == -1), 'long_entry'] = False\n",
    "    stock.loc[(stock['short_exclusion_zone'] < stock['Close']) | (stock['positions_long'] == 1), 'short_entry'] = False\n",
    "\n",
    "    # update positions based on entry and exit signals\n",
    "    stock.loc[stock['long_entry'], 'positions_long'] = 1\n",
    "    stock.loc[stock['short_entry'], 'positions_short'] = -1\n",
    "    stock.loc[stock['long_exit'], 'positions_long'] = 0\n",
    "    stock.loc[stock['short_exit'], 'positions_short'] = 0\n",
    "\n",
    "    # integrate exit conditions based on stop loss/ exclusion zones\n",
    "    stock.loc[(stock['positions_long'] == 1) & (stock['Close'] < stock['long_stop_loss']), 'positions_long'] = 0\n",
    "    stock.loc[(stock['positions_short'] == -1) & (stock['Close'] > stock['short_stop_loss']), 'positions_short'] = 0\n",
    "    stock['positions'] = stock['positions_long'] + stock['positions_short']\n",
    "\n",
    "    # no simultaneous long and short positions\n",
    "    # stock['positions'] = stock['positions_long'].combine_first(stock['positions_short'])\n",
    "\n",
    "    stock['log_returns'] = np.log(stock['Close'] / stock['Close'].shift())\n",
    "    stock['strategy_returns'] = stock['positions'].shift(1) * stock['log_returns']\n",
    "\n",
    "    # return cumulative returns\n",
    "    return stock['strategy_returns'].cumsum()\n",
    "\n",
    "    \n",
    "\n",
    "    #returns\n",
    "#     stock['positions'] = stock['positions_long'].fillna(0) + stock['positions_short'].fillna(0)\n",
    "#     stock['log_returns'] = np.log(stock['Close'] / stock['Close'].shift())\n",
    "#     stock['strategy_returns'] = stock['positions'].shift(1) * stock['log_returns']\n",
    "    \n",
    "#     return stock['strategy_returns'].cumsum()\n",
    "\n",
    "def turtle_returns(priceTable, start_date, end_date, atr_period=14, X=2, Y=2):\n",
    "    truncate_date = pd.to_datetime(start_date) + pd.DateOffset(years=1)\n",
    "    daterange = pd.date_range(start=start_date, end=end_date, freq='D')\n",
    "    totalret = pd.DataFrame(index=daterange) \n",
    "    for stock_ticker in mySymbols:\n",
    "        totalret[stock_ticker] = turtle_atr(priceTablesByTicker[stock_ticker], atr_period, X, Y)  \n",
    "    tt_sig_raw = totalret\n",
    "    tt_sig_norm = normalize(tt_sig_raw)\n",
    "    \n",
    "    rtn = priceTable.loc[start_date:end_date].pct_change() * 100\n",
    "    print(tt_sig_raw.shape) \n",
    "    tt_ranked_position = rank_bin(tt_sig_raw, 0.4)\n",
    "    \n",
    "    tt_rtn  = returns_from_positions(tt_ranked_position,  rtn, truncate_date)\n",
    "    \n",
    "    tt_SR = sharpe_ratio(tt_rtn)\n",
    "\n",
    "    # Originally return tt_rtn.cumsum()/tt_rtn.std()*0.15, tt_SR\n",
    "    return tt_rtn.cumsum()/tt_rtn.std()*0.15, tt_SR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "both_sharpe_map = {}\n",
    "turtle_sharpe_to_parameter = {} # Map\n",
    "winning_turtle_to_parameter = {} # Map from turtle sharpe to its parameters\n",
    "turtle_wins = 0\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def printSharpesInDescending(parameter, turtle_sharpe_to_parameter):\n",
    "    myKeys = list(turtle_sharpe_to_parameter.keys())  \n",
    "    myKeys.sort(reverse=True)\n",
    "    sorted_dict = {i: turtle_sharpe_to_parameter[i] for i in myKeys}\n",
    "    # Sharpe and dates printed in descending order\n",
    "    for i in myKeys:\n",
    "        print(\"Turtle Sharpe Ratio is \", i, \" for \", parameter, \" \", turtle_sharpe_to_parameter[i])\n",
    "    \n",
    "    #if len(turtle_sharpe_to_parameter[0] == 1):\n",
    "        \n",
    "        \n",
    "def printTurtleWins(parameter, winning_turtle_to_parameter):\n",
    "    print(\"Turtle performed better \",  turtle_wins, \" out of \",  total, \" times\")\n",
    "    myKeys = list(winning_turtle_to_parameter.keys())\n",
    "    myKeys.sort(reverse=True)\n",
    "    sorted_dict = {i: winning_turtle_to_parameter[i] for i in myKeys}\n",
    "\n",
    "    #Sharpe and dates printed in descending order\n",
    "    for i in myKeys:\n",
    "        print(\"Winning turtle Sharpe Ratio is \", i, \" for \", parameter, \": \", winning_turtle_to_parameter[i])\n",
    "\n",
    "def plotParameterToSharpe(x, y, data):\n",
    "    # Extracting keys and values\n",
    "    keys = list(data.keys())\n",
    "    keys.sort()\n",
    "    values = list(data.values())\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(keys, values, marker='o', linestyle='-')\n",
    "    string = 'Mapping ' +  x  + ' to ' + y\n",
    "    plt.title(string)\n",
    "    plt.xlabel(x)\n",
    "    plt.ylabel(y)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Date Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3223, 86)\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for i, dates in enumerate(date_iterations):\n",
    "    normalized_mom, normalized_mr, normalized_both, mom_sr, mr_sr, both_sr = benchmark_strategies(priceTable, *dates)\n",
    "    both_sr = round(both_sr, 2)\n",
    "    mom_sr = round(mom_sr, 2)\n",
    "    mr_sr = round(mr_sr, 2)\n",
    "    both_sharpe_map[both_sr] = (dates, normalized_mom, normalized_mr, normalized_both, mom_sr, mr_sr)\n",
    "    normalized_turtle, turtle_sr = turtle_returns(priceTable, dates[0], dates[1])\n",
    "    turtle_sr = round(turtle_sr, 2)\n",
    "    turtle_sharpe_to_parameter[turtle_sr] = dates\n",
    "    \n",
    "    data.append({\n",
    "        'Start Date': dates[0],\n",
    "        'End Date': dates[1],\n",
    "        'Combined Sharpe': both_sr,\n",
    "        'Turtle Sharpe': turtle_sr\n",
    "    })\n",
    "    if i == 0:\n",
    "        plt.figure()\n",
    "        normalized_mom.plot() # Blue\n",
    "        normalized_mr.plot() # Orange\n",
    "        normalized_both.plot() # Green\n",
    "        normalized_turtle.plot() # Red\n",
    "    if turtle_sr > both_sr:\n",
    "        turtle_wins += 1\n",
    "        winning_turtle_to_parameter[turtle_sr] = dates\n",
    "    total += 1\n",
    "    print(i)\n",
    "    if i == 0:\n",
    "        year = dates[0][:4]\n",
    "        year_num = int(year)\n",
    "        year_num += 1\n",
    "        trunc_date = str(year_num) + dates[0][4:]\n",
    "        plt.xlim(trunc_date, dates[1])\n",
    "        plt.show()\n",
    "        print(\"Date Range:\", trunc_date, \" to \", dates[1])\n",
    "        print(\"Sharpe for MoM, MR, and Both:\", mom_sr, mr_sr, both_sr)\n",
    "        print(\"Sharpe for Turtle:\", turtle_sr)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "#df.to_excel('output_file.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "printSharpesInDescending(\"dates\", turtle_sharpe_to_parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turtle performed better  0  out of  0  times\n"
     ]
    }
   ],
   "source": [
    "printTurtleWins(\"dates\", winning_turtle_to_parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different ATR Periods - DON'T RUN AGAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "both_sharpe_map = {}\n",
    "turtle_sharpe_to_parameter = {} # Map\n",
    "parameter_to_turtle_sharpe = {}\n",
    "parameter_to_graph_data = {}\n",
    "winning_turtle_to_parameter = {} # Map from turtle sharpe to its parameters\n",
    "turtle_wins = 0\n",
    "total = 0\n",
    "\n",
    "for i, atr in enumerate(atr_period_iterations):\n",
    "    normalized_turtle, turtle_sr = turtle_returns(priceTable, *date_iterations[0], atr_period=atr)\n",
    "    turtle_sr = round(turtle_sr, 2)\n",
    "    turtle_sharpe_to_parameter[turtle_sr] = atr\n",
    "    parameter_to_turtle_sharpe[atr] = turtle_sr\n",
    "    #parameter_to_graph_data[atr] = normalized_turtle    \n",
    "\n",
    "printSharpesInDescending(\"ATR Period\", turtle_sharpe_to_parameter)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plotParameterToSharpe(\"ATR\", \"Sharpe Ratio\", parameter_to_turtle_sharpe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different widths of stop loss - TAKES A LONG TIME TO RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18500/3703695038.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mtot_turtle_sr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#for j, dates in enumerate(date_iterations):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "both_sharpe_map = {}\n",
    "turtle_sharpe_to_parameter = {} # Map\n",
    "parameter_to_turtle_sharpe = {}\n",
    "parameter_to_graph_data = {}\n",
    "winning_turtle_to_parameter = {} # Map from turtle sharpe to its parameters\n",
    "turtle_wins = 0\n",
    "total = 0\n",
    "\n",
    "for i, x in enumerate(X):\n",
    "    tot_turtle_sr = 0\n",
    "    #for j, dates in enumerate(date_iterations):\n",
    "    normalized_turtle, turtle_sr = turtle_returns(priceTable, *date_iterations[0], atr_period=10, X=x)\n",
    "    turtle_sr = round(turtle_sr, 2)\n",
    "    print(x, turtle_sr)\n",
    "    tot_turtle_sr += turtle_sr\n",
    "    turtle_sr = tot_turtle_sr / (j + 1)\n",
    "    turtle_sharpe_to_parameter[turtle_sr] = x\n",
    "    parameter_to_turtle_sharpe[x] = turtle_sr\n",
    "    \n",
    "printSharpesInDescending(\"Width of the stop loss zone\", turtle_sharpe_to_parameter)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotParameterToSharpe(\"X\", \"Sharpe Ratio\", parameter_to_turtle_sharpe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different widths of position barriers - TAKES A LONG TIME TO RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_sharpe_map = {}\n",
    "turtle_sharpe_to_parameter = {} # Map\n",
    "parameter_to_turtle_sharpe = {}\n",
    "parameter_to_graph_data = {}\n",
    "winning_turtle_to_parameter = {} # Map from turtle sharpe to its parameters\n",
    "turtle_wins = 0\n",
    "total = 0\n",
    "\n",
    "for i, y in enumerate(Y):\n",
    "    tot_turtle_sr = 0\n",
    "    #for j, dates in enumerate(date_iterations):\n",
    "    normalized_turtle, turtle_sr = turtle_returns(priceTable, *date_iterations[10], atr_period=10, Y=y)\n",
    "    turtle_sr = round(turtle_sr, 2)\n",
    "    print(y, turtle_sr)\n",
    "    tot_turtle_sr += turtle_sr\n",
    "    turtle_sr = tot_turtle_sr / (j + 1)\n",
    "    turtle_sharpe_to_parameter[turtle_sr] = y\n",
    "    parameter_to_turtle_sharpe[y] = turtle_sr\n",
    "    \n",
    "printSharpesInDescending(\"width of position barrier\", turtle_sharpe_to_parameter)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
